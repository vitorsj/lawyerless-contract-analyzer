# LLM Provider Configuration
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_TIMEOUT=120

# LM Studio Configuration (Local LLM)
LM_STUDIO_MODEL=llama-3.1-8b-instruct
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_TIMEOUT=180

# FastAPI Configuration
APP_NAME=Lawyerless API
APP_VERSION=1.0.0
APP_ENV=development
DEBUG=false
LOG_LEVEL=INFO

# Server Configuration
HOST=localhost
PORT=8000
RELOAD=true

# CORS Configuration
CORS_ORIGINS=["http://localhost:3000","http://127.0.0.1:3000","https://localhost:3000","https://127.0.0.1:3000"]
CORS_ALLOW_CREDENTIALS=true

# File Processing Configuration
MAX_FILE_SIZE=52428800
MAX_PDF_PAGES=200
PDF_PROCESSING_TIMEOUT=120
PDF_CHUNK_SIZE=4000
PDF_CHUNK_OVERLAP=200

# LLM Processing Configuration
LLM_TIMEOUT=180
LLM_MAX_RETRIES=3
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4096

# Analysis Configuration
RISK_ANALYSIS_ENABLED=true
NEGOTIATION_QUESTIONS_COUNT=5

# LangSmith Configuration (Observability)
# To enable LangSmith tracing, get an API key from https://smith.langchain.com/
# and set the following variables:
LANGSMITH_API_KEY=your-langsmith-api-key-here
LANGSMITH_PROJECT=lawyerless-contract-analyzer
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_ENABLED=false
LANGSMITH_SAMPLE_RATE=1.0